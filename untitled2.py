# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nPeFFNIiqqWRyyeFFn1AGKoeli8PZhc1
"""

!pip install --quiet sentence-transformers matplotlib

from sentence_transformers import SentenceTransformer, util
import matplotlib.pyplot as plt
import numpy as np

# Lightweight embedding model (works 100%, no transformer conflicts)
embedder = SentenceTransformer("all-MiniLM-L6-v2")

print("Model loaded ✔ (No errors)")

def literature_agent(query):
    return f"""
    Literature Insights:
    The molecule shows biological relevance to {query}.
    Mechanisms and pathways support potential repurposing.
    """

def patent_agent(query):
    return f"""
    Patent Insights:
    Patent search reveals moderate freedom-to-operate for {query}.
    No critical blocking patents identified.
    """

def market_agent(query):
    return f"""
    Market Insights:
    High unmet need and commercial opportunity detected in {query}.
    Competitor density is low → high feasibility.
    """

def internal_docs_agent(query):
    return f"""
    Internal R&D Insights:
    Previous internal studies align with potential repurposing for {query}.
    Shows strong developmental feasibility.
    """

def master_agent(query):

    # Collect outputs
    outputs = [
        literature_agent(query),
        patent_agent(query),
        market_agent(query),
        internal_docs_agent(query)
    ]

    # Embeddings for semantic similarity (accuracy metric)
    query_emb = embedder.encode(query)
    output_embs = embedder.encode(outputs)

    # Cosine similarity used as "accuracy"
    sims = [float(util.cos_sim(query_emb, emb)) for emb in output_embs]
    accuracy = round(np.mean(sims) * 100, 2)

    summary = f"""
    Summary for: {query}

    • Literature supports repurposing potential.
    • Patent landscape suggests moderate FTO.
    • Market demand indicates strong commercial relevance.
    • Internal R&D data supports feasibility.

    → System Confidence (Accuracy): {accuracy}%
    """

    return {
        "query": query,
        "summary": summary,
        "accuracy": accuracy,
        "similarities": sims,
        "outputs": outputs
    }

query = "repurposing approved molecule for oncology and immunology applications"

result = master_agent(query)
result

plt.figure(figsize=(8,5))
plt.bar(["Literature", "Patent", "Market", "Internal"], result["similarities"], color="cornflowerblue")
plt.title("Agent Similarity Scores (Accuracy Breakdown)")
plt.ylabel("Similarity Score")
plt.ylim(0, 1)
plt.grid(alpha=0.3)

plt.savefig("accuracy_chart.png", dpi=300)
"accuracy_chart.png"

plt.figure(figsize=(10,6))

plt.text(0.1, 0.85, "1. User Query Input", fontsize=16)
plt.text(0.1, 0.72, "2. Master Agent Interprets Query", fontsize=16)
plt.text(0.1, 0.60, "3. Worker Agents Execute:", fontsize=16)
plt.text(0.15, 0.53, "- Literature Agent", fontsize=14)
plt.text(0.15, 0.47, "- Patent Agent", fontsize=14)
plt.text(0.15, 0.41, "- Market Agent", fontsize=14)
plt.text(0.15, 0.35, "- Internal Docs Agent", fontsize=14)
plt.text(0.1, 0.22, "4. Master Agent Synthesizes Outputs", fontsize=16)
plt.text(0.1, 0.12, "5. Generates Accuracy Score + Summary", fontsize=16)

plt.axis("off")
plt.savefig("flowchart.png", dpi=300)
"flowchart.png"

query = "Repurposing approved molecule for oncology and immunology applications"

result = master_agent(query)
result

# run once
!pip install --quiet sentence-transformers pandas matplotlib fpdf

# safe imports
from sentence_transformers import SentenceTransformer, util
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from fpdf import FPDF
import os

# Load a lightweight sentence embedding model (fast, stable)
embedder = SentenceTransformer("all-MiniLM-L6-v2")
print("Embedder loaded ✔")

# Small sample dataset you can expand or replace with your files
drugs = [
    {"name":"DrugA", "desc":"Small molecule, kinase inhibitor used in inflammation and immune modulation."},
    {"name":"DrugB", "desc":"Antiviral nucleoside analog with known safety in humans."},
    {"name":"DrugC", "desc":"Small molecule used in hypertension, affects vascular remodeling."},
    {"name":"DrugD", "desc":"Metabolic modulator with data suggesting anti-cancer synergy."},
    {"name":"DrugE", "desc":"Generic analgesic with anti-inflammatory properties."}
]
drugs_df = pd.DataFrame(drugs)

# Mock patent risk scores (0 = low, 1 = high), market opportunity (0-1), internal evidence (0-1)
meta = {
 "DrugA": {"patent_risk":0.2, "market":0.8, "internal_support":0.9},
 "DrugB": {"patent_risk":0.6, "market":0.4, "internal_support":0.3},
 "DrugC": {"patent_risk":0.1, "market":0.5, "internal_support":0.2},
 "DrugD": {"patent_risk":0.4, "market":0.9, "internal_support":0.8},
 "DrugE": {"patent_risk":0.05, "market":0.3, "internal_support":0.1}
}

# Each "agent" returns a small textual evidence snippet and a score (0-1).
# In a production system these would call PubMed, USPTO, IQVIA APIs.

def literature_agent(query, drug_desc):
    # compute semantic similarity between query (disease) and drug description
    sim = float(util.cos_sim(embedder.encode(query), embedder.encode(drug_desc)))
    snippet = f"Literature similarity score={sim:.3f}: matches mechanism keywords and pathways."
    return {"text": snippet, "score": sim}

def patent_agent(drug_name):
    risk = meta[drug_name]["patent_risk"]
    score = 1.0 - risk  # higher is better (lower patent risk => higher score)
    snippet = f"Patent risk={risk:.2f} (simulated)."
    return {"text": snippet, "score": score}

def market_agent(drug_name):
    m = meta[drug_name]["market"]
    snippet = f"Market opportunity score={m:.2f} (simulated)."
    return {"text": snippet, "score": m}

def internal_agent(drug_name):
    s = meta[drug_name]["internal_support"]
    snippet = f"Internal evidence score={s:.2f} (simulated historical R&D data)."
    return {"text": snippet, "score": s}

def evaluate_candidates(disease_query, drugs_df):
    q = disease_query
    results = []
    # precompute query embedding
    # (embedding reused to speed multiple similarity calls)
    q_emb = embedder.encode(q)

    for _, row in drugs_df.iterrows():
        name = row['name']
        desc = row['desc']
        # literature worker uses precomputed query embedding (slightly modified to use embedder.encode already)
        lit = literature_agent(q, desc)
        pat = patent_agent(name)
        mar = market_agent(name)
        internal = internal_agent(name)

        # Weighted aggregate scoring (you can change weights in demo)
        weights = {"lit":0.4, "patent":0.15, "market":0.25, "internal":0.2}
        aggregate = (lit["score"]*weights["lit"] +
                     pat["score"]*weights["patent"] +
                     mar["score"]*weights["market"] +
                     internal["score"]*weights["internal"])
        results.append({
            "drug": name,
            "lit_snippet": lit["text"],
            "patent_snippet": pat["text"],
            "market_snippet": mar["text"],
            "internal_snippet": internal["text"],
            "aggregate_score": aggregate,
            "lit_score": lit["score"],
            "patent_score": pat["score"],
            "market_score": mar["score"],
            "internal_score": internal["score"]
        })
    # rank by aggregate_score descending
    results = sorted(results, key=lambda x: x["aggregate_score"], reverse=True)
    return results

# Example run
disease = "Immuno-oncology: tumor immune microenvironment modulation and checkpoint pathways"
ranked = evaluate_candidates(disease, drugs_df)
pd.DataFrame(ranked)[:10]

# Create dataframe and save CSV for archival
out_df = pd.DataFrame(ranked)
out_df.to_csv("candidate_ranking.csv", index=False)
print("Saved candidate_ranking.csv")

# Quick table image using matplotlib
def save_table_image(df, filename="candidates_table.png"):
    fig, ax = plt.subplots(figsize=(10, len(df)*0.6 + 1))
    ax.axis('off')
    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc="left", loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 1.1)
    plt.tight_layout()
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.close()
    return filename

table_png = save_table_image(out_df[["drug","aggregate_score","lit_score","patent_score","market_score","internal_score"]], "candidates_table.png")
table_png

# Bar chart for top N candidates
topN = 5
top = out_df[:topN]

# stacked component bars to show contribution
labels = top['drug'].tolist()
lit = top['lit_score'].tolist()
pat = top['patent_score'].tolist()
mar = top['market_score'].tolist()
intg = top['internal_score'].tolist()

x = np.arange(len(labels))
width = 0.6

plt.figure(figsize=(10,5))
plt.bar(x, lit, width, label='Literature', color='#4a90e2')
plt.bar(x, pat, width, bottom=lit, label='Patent', color='#50e3c2')
bottom2 = np.array(lit) + np.array(pat)
plt.bar(x, mar, width, bottom=bottom2, label='Market', color='#f5a623')
bottom3 = bottom2 + np.array(mar)
plt.bar(x, intg, width, bottom=bottom3, label='Internal', color='#d0021b')

plt.xticks(x, labels)
plt.ylabel('Component scores (stacked)')
plt.title('Top candidates - component contribution')
plt.legend()
plt.tight_layout()
plt.savefig('candidates_components.png', dpi=300)
plt.close()
"candidates_components.png"

# Wireframe 1: Dashboard summary (big header, top candidate, score)
plt.figure(figsize=(11,6))
plt.text(0.02, 0.88, "Agentic AI Dashboard — Repurposing Search", fontsize=20, weight='bold')
plt.text(0.02, 0.76, f"Query: {disease}", fontsize=12)
plt.text(0.02, 0.68, "Top candidate:", fontsize=14)
plt.text(0.15, 0.68, f"{out_df.iloc[0]['drug']} (score: {out_df.iloc[0]['aggregate_score']:.3f})", fontsize=18, color='#4a90e2')
plt.text(0.02, 0.55, "Summary:", fontsize=12)
plt.text(0.02, 0.48, out_df.iloc[0]['lit_snippet'], fontsize=10)
plt.text(0.02, 0.36, out_df.iloc[0]['patent_snippet'], fontsize=10)
plt.text(0.02, 0.24, out_df.iloc[0]['market_snippet'], fontsize=10)
plt.text(0.02, 0.12, out_df.iloc[0]['internal_snippet'], fontsize=10)
plt.axis('off')
plt.savefig("dashboard_wireframe_topcandidate.png", dpi=300, bbox_inches='tight')
plt.close()
"dashboard_wireframe_topcandidate.png"

# list outputs
for f in ["candidate_ranking.csv", "candidates_table.png", "candidates_components.png",
          "dashboard_wireframe_topcandidate.png", "agentic_candidate_report.pdf"]:
    print(f, "->", os.path.exists(f))

from PIL import Image
from IPython.display import display, HTML
import os

# list of image filenames produced earlier
files_to_show = [
    "candidates_table.png",
    "candidates_components.png",
    "dashboard_wireframe_topcandidate.png",
    "accuracy_chart.png",
    "flowchart.png",
    "system_flowchart.png"
]

found = []
for f in files_to_show:
    if os.path.exists(f):
        found.append(f)

if not found:
    html = "<h3>No generated images found in current directory.</h3>"
    html += "<p>Files currently available:</p><ul>"
    for fn in os.listdir("."):
        html += f"<li>{fn}</li>"
    html += "</ul>"
    display(HTML(html))
else:
    for f in found:
        try:
            display(HTML(f"<h3>{f}</h3>"))
            display(Image.open(f))
        except Exception as e:
            display(HTML(f"<p>Error displaying {f}: {e}</p>"))

# Download links
html_links = "<h3>Download links</h3><ul>"
for f in found:
    html_links += f'<li><a href="{f}" target="_blank">{f}</a></li>'
html_links += "</ul>"
display(HTML(html_links))